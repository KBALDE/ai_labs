{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "568efd3c",
   "metadata": {},
   "source": [
    "# How to make data ready for Deep Learning Algorithms?\n",
    "\n",
    "This is a big challenge!!! I want to generalize the read and pre-process step for any use case.\n",
    "\n",
    "This depends on :\n",
    "- the type of the data that is processed. Is it a text, an image or just a structured data\n",
    "- the model that is going to consume the data for training. Is it an NN, a CNN, an RNN?\n",
    "- the nature of the messy data. How messy the data is? dirty data!!!!\n",
    "\n",
    "Let's go from the hypothese that data is like the one that found in Kaggle platform. So just normal data, that are very influenced by its type.\n",
    "\n",
    "But Why I am trying to do that?\n",
    "Because I find it hard and hate wasting time just find the way to read data and make it ready.\n",
    "\n",
    "\n",
    "Let's start with image data and text data, and audio data to finish with structured data.\n",
    "\n",
    "\n",
    "Do not forget that the target reader is keras or tensorflow!!!\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "f793d008",
   "metadata": {},
   "source": [
    "## Image Data Reading and Preprocessing\n",
    "\n",
    "Let's go from what exist !!!\n",
    "- Keras data processing and \n",
    "- tensorflow data processing\n",
    "\n",
    "\n",
    "### Here the way keras read data \n",
    "Keras dataset preprocessing utilities, located at `tf.keras.preprocessing`, help you go from raw data on disk to a `tf.data.Dataset` object that can be used to train a model.\n",
    "\n",
    "Here's a quick example: let's say you have 10 folders, each containing 10,000 images from a different category, and you want to train a classifier that maps an image to its category. Your training data folder would look like this:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "\n",
    "You may also have a validation data folder validation_data/ structured in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d731f1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "train_ds = image_dataset_from_directory(\n",
    "    directory='training_data/',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256))\n",
    "\n",
    "validation_ds = image_dataset_from_directory(\n",
    "    directory='validation_data/',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256))\n",
    "\n",
    "model = keras.applications.Xception(weights=None, input_shape=(256, 256, 3), classes=10)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.fit(train_ds, epochs=10, validation_data=validation_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37877b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "def imgReadSubDir(dirList, batch_size=batch_size, image_size=image_size):\n",
    "    \"\"\"\n",
    "    argument \n",
    "      - dirList: list of subdirectories\n",
    "      - batch_size\n",
    "      - image_size\n",
    "    return \n",
    "      - tf datasets: training, validation and/or test data, depending on the list\n",
    "\n",
    "    \"\"\"\n",
    "    for d in disrList:\n",
    "        return image_dataset_from_directory(directory=d,\n",
    "                                            labels='inferred',\n",
    "                                            label_mode='categorical',\n",
    "                                            batch_size=batch_size,\n",
    "                                            image_size=image_size)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0fedc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b127ffa4",
   "metadata": {},
   "source": [
    "### image_dataset_from_directory function\n",
    "Generates a `tf.data.Dataset` from image files in a directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f988b362",
   "metadata": {},
   "source": [
    "Then calling `image_dataset_from_directory(main_directory, labels='inferred')` will return a `tf.data.Dataset` that yields batches of images from the subdirectories class_a and class_b, together with labels 0 and 1 (0 corresponding to class_a and 1 corresponding to class_b).\n",
    "\n",
    "Supported image formats: jpeg, png, bmp, gif. Animated gifs are truncated to the first frame."
   ]
  },
  {
   "cell_type": "raw",
   "id": "9d8688a8",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"directory\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False,\n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09fc1db",
   "metadata": {},
   "source": [
    "## load_img function\n",
    "It loads image into PIL format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0896af94",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.preprocessing.image.load_img(\n",
    "    path, grayscale=False, color_mode=\"rgb\", target_size=None, interpolation=\"nearest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d93b70f8",
   "metadata": {},
   "source": [
    "#Usage:\n",
    "\n",
    "image = tf.keras.preprocessing.image.load_img(image_path)\n",
    "input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "input_arr = np.array([input_arr])  # Convert single image to a batch.\n",
    "predictions = model.predict(input_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d543d9d0",
   "metadata": {},
   "source": [
    "## img_to_array function\n",
    "convert a PIL image to an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7fcd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_to_array function\n",
    "tf.keras.preprocessing.image.img_to_array(img, data_format=None, dtype=None)\n",
    "Converts a PIL Image instance to a Numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1678c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usage\n",
    "from PIL import Image\n",
    "\n",
    "img_data = np.random.random(size=(100, 100, 3))\n",
    "\n",
    "img = tf.keras.preprocessing.image.array_to_img(img_data)\n",
    "\n",
    "array = tf.keras.preprocessing.image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5956a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6eeb9f2",
   "metadata": {},
   "source": [
    "ref : https://keras.io/api/preprocessing/image/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c572f0e",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "If your aim is to creatz tensorflow datasets you have subdivide your data into train/valid or test set and then subdivide them again with respect to the number of classes you want to use in the model.\n",
    "\n",
    "\n",
    "I could create function above it that return a tensor dataset ready to be pushed in models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee340d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2a1e53d",
   "metadata": {},
   "source": [
    "# Timeseries data preprocessing\n",
    "\n",
    "**timeseries_dataset_from_array** function\n",
    "\n",
    "\n",
    "Creates a dataset of sliding windows over a timeseries provided as array.\n",
    "\n",
    "This function takes in a sequence of data-points gathered at equal intervals, along with time series parameters such as length of the sequences/windows, spacing between two sequence/windows, etc., to produce batches of timeseries inputs and targets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4d92a2c7",
   "metadata": {},
   "source": [
    "#timeseries_dataset_from_array function\n",
    "tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "    data,\n",
    "    targets,\n",
    "    sequence_length,\n",
    "    sequence_stride=1,\n",
    "    sampling_rate=1,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    seed=None,\n",
    "    start_index=None,\n",
    "    end_index=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c832924f",
   "metadata": {},
   "source": [
    "It returns a `tf.data.Dataset` instance. If targets was passed, the dataset yields tuple `(batch_of_sequences, batch_of_targets)`. If not, the dataset yields only `batch_of_sequences`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9794784b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#np.ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91930552",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.random.randn(110,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0cb96ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:-10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc087096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66a2ea0b",
   "metadata": {},
   "source": [
    "## Example 2: Temporal regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe16af2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = data[:-10]\n",
    "targets = data[10:]\n",
    "\n",
    "dataset = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "    input_data, targets, sequence_length=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "296fa3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataset:\n",
    "    inputs, targets = batch\n",
    "    assert np.array_equal(inputs[0], data[:10])  # First sequence: steps [0-9]\n",
    "    assert np.array_equal(targets[0], data[10])  # Corresponding target: step 10\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb410444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(next(iter(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05991a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([91, 10, 1]), TensorShape([91, 1]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape, targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567b7793",
   "metadata": {},
   "source": [
    "## Example 3: Temporal regression for many-to-many architectures.\n",
    "\n",
    "Consider two arrays of scalar values X and Y, both of shape (100,). The resulting dataset should consist samples with 20 timestamps each. The samples should not overlap. To generate a dataset that uses the current timestamp to predict the corresponding target timestep, you would use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2d7f1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = np.arange(100)\n",
    "Y = X*2\n",
    "\n",
    "sample_length = 20\n",
    "input_dataset = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "  X, None, sequence_length=sample_length, sequence_stride=sample_length)\n",
    "target_dataset = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "  Y, None, sequence_length=sample_length, sequence_stride=sample_length)\n",
    "\n",
    "for batch in zip(input_dataset, target_dataset):\n",
    "    inputs, targets = batch\n",
    "    assert np.array_equal(inputs[0], X[:sample_length])\n",
    "  \n",
    "    # second sample equals output timestamps 20-40\n",
    "    assert np.array_equal(targets[1], Y[sample_length:2*sample_length])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976780f5",
   "metadata": {},
   "source": [
    "*the question is how we choose the sample_length*\n",
    "\n",
    "It is like we are using a 20 sample time step to compute one output, the prediction.\n",
    "But what if we have many different time step? We have to create as many colimns as we need???\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08d39bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5, 20])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d4cba3",
   "metadata": {},
   "source": [
    "### Pads sequences to the same length.\n",
    "\n",
    "This function transforms a list (of length num_samples) of sequences `(lists of integers)` into a 2D Numpy array of shape `(num_samples, num_timesteps)`. num_timesteps is either the maxlen argument if provided, or the length of the longest sequence in the list.\n",
    "\n",
    "- `Sequences that are shorter than num_timesteps are padded with value until they are num_timesteps long`.\n",
    "\n",
    "-  Sequences longer than num_timesteps are truncated so that they fit the desired length.\n",
    "\n",
    "The position where padding or truncation happens is determined by the arguments padding and truncating, respectively. Pre-padding or removing values from the beginning of the sequence is the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7523f8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad_sequences function\n",
    "tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    sequences, maxlen=None, dtype=\"int32\", padding=\"pre\", truncating=\"pre\", value=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fcbbc33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 2, 3],\n",
       "       [4, 5, 6]], dtype=int32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = [[1], [2, 3], [4, 5, 6]]\n",
    "tf.keras.preprocessing.sequence.pad_sequences(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39a5c5fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1, -1,  1],\n",
       "       [-1,  2,  3],\n",
       "       [ 4,  5,  6]], dtype=int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.preprocessing.sequence.pad_sequences(sequence, value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "255854bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [2, 3, 0],\n",
       "       [4, 5, 6]], dtype=int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.preprocessing.sequence.pad_sequences(sequence, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1daefff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [5, 6]], dtype=int32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8471c26",
   "metadata": {},
   "source": [
    "ref : https://keras.io/api/preprocessing/timeseries/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e27675a",
   "metadata": {},
   "source": [
    "# Text data preprocessing\n",
    "text_dataset_from_directory function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c81198",
   "metadata": {},
   "source": [
    "Then calling text_dataset_from_directory(main_directory, labels='inferred') will return a tf.data.Dataset that yields batches of texts from the subdirectories class_a and class_b, together with labels 0 and 1 (0 corresponding to class_a and 1 corresponding to class_b).\n",
    "\n",
    "Only .txt files are supported at this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0746b40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    directory,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    class_names=None,\n",
    "    batch_size=32,\n",
    "    max_length=None,\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    follow_links=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0a0c15",
   "metadata": {},
   "source": [
    "Like keras image reader from directory we can read text too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458c7191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8608853b",
   "metadata": {},
   "source": [
    "# Read and Process RAW Image and make it KerABLE\n",
    "\n",
    "what if keras read from directory could do it?\n",
    "\n",
    "Let's see!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc50340",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.preprocessing.image.load_img(\n",
    "    path, grayscale=False, color_mode=\"rgb\", target_size=None, interpolation=\"nearest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859b452e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56258ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kindi/Documents/PROG/AI_LABS\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c906e02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def getFileNamesList(formatta, imagePath):\n",
    "    \"\"\"\n",
    "    argument: choose among '.jpeg', '.png', '.gif'\n",
    "    return: list of files in a directory\n",
    "    \"\"\"\n",
    "    path = imagePath\n",
    "\n",
    "    folder = os.fsencode(path)\n",
    "    \n",
    "    filenames = []\n",
    "    \n",
    "    for file in os.listdir(folder):\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename.endswith( (formatta) ): \n",
    "            filenames.append(filename)\n",
    "    return filenames\n",
    "\n",
    "\n",
    "def readImageFromDirectory(target_size, fileNameList, nb_channel ):\n",
    "    \"\"\"\n",
    "    target_size: the 1D shape of the image to output\n",
    "    fileNameList: file gotten from the directory\n",
    "    nb_channel: number of channel of the input image\n",
    "    \n",
    "    return: 4D shape numpy array\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    m=len(fileNameList)\n",
    "    \n",
    "    ND=np.arange(m*target_size[0]*target_size[1]*nb_channel).reshape(m, target_size[0],target_size[1],nb_channel)\n",
    "    \n",
    "    for im in range(ND.shape[0]):\n",
    "        \n",
    "        img=tf.keras.preprocessing.image.load_img(\n",
    "            imagePath+str(fileNameList[im]), grayscale=False, color_mode=\"rgb\", target_size=target_size,\n",
    "            interpolation=\"nearest\")\n",
    "        \n",
    "        array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        \n",
    "        ND[im]=array\n",
    "    \n",
    "    return ND \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622f088c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec5ffc95",
   "metadata": {},
   "source": [
    "# Read and Process RAW Text data and make it KerABLE\n",
    "\n",
    "L'objectif comme précédement est de construire une fonction qui permet de lire du text et rendre cette donnée Prête à etre inputer dans un model de type Keras ou tensorflow.\n",
    "\n",
    "Pourquoi tu construis sur ces frameworks? non seulmement facile d'accès pour moi, mais ils sont fiables.\n",
    "\n",
    "On peut lire un texte de plusieurs façon :\n",
    "\n",
    "- read from directory like image: in this case the texte should be in .txt format. In this case, we can use pandas or else to preprocasse the data in such a way that it is readable by keras read from directory method.\n",
    "\n",
    "- read a fat file and make it kerable\n",
    "\n",
    "- read one sentence or phrace and make it kerable ( make it ready to be used in keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3e93f3",
   "metadata": {},
   "source": [
    "## Text vectorization layer.\n",
    "\n",
    "This layer has basic options for managing text in a Keras model. It transforms a batch of strings (`one example = one string`) into either a list of token indices (`one example = 1D tensor of integer token indices`) or a dense representation (`one example = 1D tensor of float values representing data about the example's tokens`).\n",
    "\n",
    "If desired, the user can call this layer's `adapt()` method on a dataset. When this layer is adapted, \n",
    "- it will analyze the dataset, \n",
    "- determine the frequency of individual string values, \n",
    "- and create a 'vocabulary' from them. This vocabulary can have unlimited size or be capped, depending on the configuration options for this layer; if there are more unique values in the input than the maximum vocabulary size, the most frequent terms will be used to create the vocabulary.\n",
    "\n",
    "The processing of each example contains the following steps:\n",
    "\n",
    "- `Standardize` each example (usually lowercasing + punctuation stripping)\n",
    "- `Split` each example into substrings (usually words)\n",
    "- `Recombine substrings` into tokens (usually ngrams)\n",
    "- `Index tokens` (associate a unique int value with each token)\n",
    "- `Transform` each example using this index, either into a vector of ints or a dense float vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63e0d59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e28cf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dataset = tf.data.Dataset.from_tensor_slices([\"foo\", \"bar\", \"baz\"])\n",
    "max_features = 5000  # Maximum vocab size.\n",
    "max_len = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d8565a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'foo'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(text_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3040776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the layer.\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "max_tokens=max_features,\n",
    "output_mode='int',\n",
    "output_sequence_length=max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eabe4e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer.adapt(text_dataset.batch(64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "43b3c769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'foo', 'baz', 'bar']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a55932a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model that uses the vectorize text layer\n",
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "63bb7e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.Input(shape=(1,), dtype=tf.string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f7e4bf3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ccd3fb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(vectorize_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "32025a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text_vectorization (TextVect (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a66a3029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 4, 1],\n",
       "       [1, 3, 0, 0]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# layer to map these integers to learned embeddings.\n",
    "input_data = [[\"#foo !qux bar ?kindi \"], [\"qux## baz??\"]]\n",
    "model.predict(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "104f1060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0, 0],\n",
       "       [4, 0, 0, 0],\n",
       "       [3, 0, 0, 0]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data=[\"foo\", \"bar\", \"baz\"]\n",
    "model.predict(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4775e133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['#foo !qux bar ?kindi '], ['qux## baz??']]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ed8871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d293d263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 4, 0],\n",
       "       [1, 3, 0, 0]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_features = 5000  # Maximum vocab size.\n",
    "max_len = 4  # Sequence length to pad the outputs to.\n",
    "\n",
    "# Create the layer.\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "max_tokens=max_features,\n",
    "output_mode='int',\n",
    "output_sequence_length=max_len)\n",
    "\n",
    "vectorize_layer.adapt(text_dataset.batch(64))\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
    "\n",
    "\n",
    "model.add(vectorize_layer)\n",
    "\n",
    "\n",
    "input_data = [[\"foo qux bar\"], [\"qux baz\"]]\n",
    "\n",
    "model.predict(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479a75f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp=[[x] for x in india_rest.text.to_list() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb1514d",
   "metadata": {},
   "outputs": [],
   "source": [
    " text_dataset = tf.data.Dataset.from_tensor_slices(dfColToList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9cc8e1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readStringsDfToDs(df, col):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices([ [x] for x in df[col].to_list() ])\n",
    "    return dataset\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb75b374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "def computeMaxLenght(df, col):\n",
    "    \"\"\"\n",
    "    arguments:df col list \n",
    "    return: an approximate maxlen\n",
    "    \"\"\"\n",
    "    com = [ [x] for x in df[col].to_list() ]\n",
    "    L = []\n",
    "    cpt = []\n",
    "    \n",
    "    for k in com:\n",
    "        for i in k:\n",
    "            L.append(word_tokenize(i))\n",
    "    for i in L:\n",
    "        cpt.append(len(i))\n",
    "        \n",
    "    return int(np.quantile(cpt, 0.8))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d2a560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "2cd9f01a",
   "metadata": {},
   "source": [
    "def readTextFromList():\n",
    "    \n",
    "    text_dataset = tf.data.Dataset.from_tensor_slices(dfColToList)\n",
    "    \n",
    "    vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "                            max_tokens=max_features,\n",
    "                            output_mode='int',\n",
    "                            output_sequence_length=max_len)\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d919ebd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbae0f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can vectorize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63f0cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5311bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dataset = tf.data.Dataset.from_tensor_slices([\"foo\", \"bar\", \"baz\"])\n",
    "max_features = 5000  # Maximum vocab size.\n",
    "max_len = 4  # Sequence length to pad the outputs to.\n",
    "\n",
    "# Create the layer.\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "max_tokens=max_features,\n",
    "output_mode='int',\n",
    "output_sequence_length=max_len)\n",
    "\n",
    "# Now that the vocab layer has been created, call `adapt` on the text-only\n",
    "# dataset to create the vocabulary. You don't have to batch, but for large\n",
    "# datasets this means we're not keeping spare copies of the dataset.\n",
    "vectorize_layer.adapt(text_dataset.batch(64))\n",
    "\n",
    "# Create the model that uses the vectorize text layer\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# Start by creating an explicit input layer. It needs to have a shape of\n",
    "# (1,) (because we need to guarantee that there is exactly one string\n",
    "# input per batch), and the dtype needs to be 'string'.\n",
    "model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
    "\n",
    "# The first layer in our model is the vectorization layer. After this\n",
    "# layer, we have a tensor of shape (batch_size, max_len) containing vocab\n",
    "# indices.\n",
    "model.add(vectorize_layer)\n",
    "\n",
    "# Now, the model can map strings to integers, and you can add an embedding\n",
    "# layer to map these integers to learned embeddings.\n",
    "\n",
    "input_data = [[\"foo qux bar\"], [\"qux baz\"]]\n",
    "\n",
    "model.predict(input_data)\n",
    "#array([[2, 1, 4, 0],\n",
    " #      [1, 3, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daba353e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from above create a function that can assess an input ready to be kerable and return yes or no\n",
    "# or just print result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c042cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can use the predict method to ensure that our data can be read by keras as validation step\n",
    "\n",
    "# Each element of the list is taking as an example\n",
    "\n",
    "# Thus it can accept a list of list and each as a sentence or phrase and comment or review or else...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4486416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the next step is to try understand callable function and what I could expect them to do.\n",
    "# keras vectorizer function is limmited, you can add your own function.\n",
    "\n",
    "# I am not that good with regex, so just copy one.....\n",
    "\n",
    "# for now just create a function that can read list of strings and return kerable input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058d1ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c654e6c",
   "metadata": {},
   "source": [
    "# Read and Process RAW TimeSeries data and make it KerABLE\n",
    "\n",
    "\n",
    "Creates a dataset `of sliding windows over a timeseries` provided as array.\n",
    "\n",
    "This function takes in a sequence of data-points gathered at `equal intervals`, along with time series parameters such as `length of the sequences/windows`, spacing between two sequence/windows, etc., `to produce batches of timeseries inputs and targets`.\n",
    "\n",
    "# `timeseries_dataset_from_array` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26a565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#timeseries_dataset_from_array function\n",
    "\n",
    "tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "    data,\n",
    "    targets,\n",
    "    sequence_length,\n",
    "    sequence_stride=1,\n",
    "    sampling_rate=1,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    seed=None,\n",
    "    start_index=None,\n",
    "    end_index=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b7c750",
   "metadata": {},
   "source": [
    "**Arguments**\n",
    "\n",
    "- `data`: Numpy array or eager tensor containing `consecutive data points` (timesteps). Axis 0 is expected to be the time dimension. (`rows` of the numpy array)\n",
    "- `targets`: Targets corresponding to timesteps in data. `targets[i] should be the target corresponding to the window that starts at index i` (see example 2 below). Pass `None` if you don't have target data (in this case the dataset will only yield the input data).\n",
    "- `sequence_length`: Length of the output sequences (in `number of timesteps`).\n",
    "- `sequence_stride`: Period between successive output sequences. `For stride s, output samples would start at index data[i], data[i + s], data[i + 2 * s], etc`.\n",
    "- `sampling_rate`: Period between successive `individual timesteps` within sequences. For rate r, timesteps data[i], data[i + r], ... data[i + sequence_length] are used for create a sample sequence.\n",
    "- `batch_size`: Number of timeseries samples in each batch (except maybe the last one).\n",
    "- `shuffle`: Whether to shuffle output samples, or instead draw them in chronological order.\n",
    "- `seed`: Optional int; random seed for shuffling.\n",
    "- `start_index`: Optional int; data points earlier (exclusive) than start_index will not be used in the output sequences. This is useful to reserve part of the data for test or validation.\n",
    "- `end_index`: Optional int; data points later (exclusive) than end_index will not be used in the output sequences. This is useful to reserve part of the data for test or validation.\n",
    "\n",
    "**Returns**\n",
    "\n",
    "- A `tf.data.Dataset` instance. If targets was passed, the dataset yields tuple `(batch_of_sequences, batch_of_targets)`. If not, the dataset yields only batch_of_sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bc02353e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.rand(99, 1)\n",
    "X=[x for x in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b95544bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(X)\n",
    "Y=X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "db36a281",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:-10]\n",
    "Y=X[10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cda9bba",
   "metadata": {},
   "source": [
    "Consider indices [0, 1, ... 99]. With \n",
    "- `sequence_length=10`,\n",
    "- `sampling_rate=2`, \n",
    "- `sequence_stride=3`, \n",
    "- `shuffle=False`, \n",
    "\n",
    "\n",
    "the dataset will yield batches of sequences composed of the following indices:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "47348a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfd=tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "    X,\n",
    "    targets=Y,\n",
    "    sequence_length =10,\n",
    "    sequence_stride=3,\n",
    "    sampling_rate=2,\n",
    "#    batch_size=128,\n",
    "    shuffle=False\n",
    "    #seed=None,\n",
    "    #start_index=None,\n",
    "    #end_index=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "afa2d589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([[ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18],\n",
       "         [ 3,  5,  7,  9, 11, 13, 15, 17, 19, 21],\n",
       "         [ 6,  8, 10, 12, 14, 16, 18, 20, 22, 24],\n",
       "         [ 9, 11, 13, 15, 17, 19, 21, 23, 25, 27],\n",
       "         [12, 14, 16, 18, 20, 22, 24, 26, 28, 30],\n",
       "         [15, 17, 19, 21, 23, 25, 27, 29, 31, 33],\n",
       "         [18, 20, 22, 24, 26, 28, 30, 32, 34, 36],\n",
       "         [21, 23, 25, 27, 29, 31, 33, 35, 37, 39],\n",
       "         [24, 26, 28, 30, 32, 34, 36, 38, 40, 42],\n",
       "         [27, 29, 31, 33, 35, 37, 39, 41, 43, 45],\n",
       "         [30, 32, 34, 36, 38, 40, 42, 44, 46, 48],\n",
       "         [33, 35, 37, 39, 41, 43, 45, 47, 49, 51],\n",
       "         [36, 38, 40, 42, 44, 46, 48, 50, 52, 54],\n",
       "         [39, 41, 43, 45, 47, 49, 51, 53, 55, 57],\n",
       "         [42, 44, 46, 48, 50, 52, 54, 56, 58, 60],\n",
       "         [45, 47, 49, 51, 53, 55, 57, 59, 61, 63],\n",
       "         [48, 50, 52, 54, 56, 58, 60, 62, 64, 66],\n",
       "         [51, 53, 55, 57, 59, 61, 63, 65, 67, 69],\n",
       "         [54, 56, 58, 60, 62, 64, 66, 68, 70, 72],\n",
       "         [57, 59, 61, 63, 65, 67, 69, 71, 73, 75],\n",
       "         [60, 62, 64, 66, 68, 70, 72, 74, 76, 78],\n",
       "         [63, 65, 67, 69, 71, 73, 75, 77, 79, 81],\n",
       "         [66, 68, 70, 72, 74, 76, 78, 80, 82, 84],\n",
       "         [69, 71, 73, 75, 77, 79, 81, 83, 85, 87],\n",
       "         [72, 74, 76, 78, 80, 82, 84, 86, 88, 90],\n",
       "         [75, 77, 79, 81, 83, 85, 87, 89, 91, 93],\n",
       "         [78, 80, 82, 84, 86, 88, 90, 92, 94, 96]]),\n",
       "  array([ 0,  3,  6,  9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45, 48,\n",
       "         51, 54, 57, 60, 63, 66, 69, 72, 75, 78]))]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tfd.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c5a298",
   "metadata": {},
   "source": [
    "In this case the last 3 data points are discarded since no full sequence can be generated to include them (the next sequence would have started at index 81, and thus its last step would have gone over 99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68aa45e",
   "metadata": {},
   "source": [
    "## Temporal regression.\n",
    "\n",
    "Consider an array data of scalar values, of `shape (steps,)`. To generate a dataset that uses the past 10 timesteps to predict the next timestep, you would use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21af0df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = data[:-10]\n",
    "targets = data[10:]\n",
    "dataset = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "    input_data, targets, sequence_length=10)\n",
    "for batch in dataset:\n",
    "    inputs, targets = batch\n",
    "    assert np.array_equal(inputs[0], data[:10])  # First sequence: steps [0-9]\n",
    "    assert np.array_equal(targets[0], data[10])  # Corresponding target: step 10\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf21906",
   "metadata": {},
   "source": [
    "## Temporal regression for many-to-many architectures.\n",
    "\n",
    "Consider two arrays of scalar values `X and Y`, both of shape `(100,)`. The resulting dataset should consist samples with `20 timestamps each`. The samples should not `overlap`. To generate a dataset that uses the current timestamp to predict the corresponding target timestep, you would use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e1a4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(100)\n",
    "Y = X*2\n",
    "\n",
    "sample_length = 20\n",
    "input_dataset = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "  X, None, sequence_length=sample_length, sequence_stride=sample_length)\n",
    "\n",
    "target_dataset = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "  Y, None, sequence_length=sample_length, sequence_stride=sample_length)\n",
    "\n",
    "for batch in zip(input_dataset, target_dataset):\n",
    "    inputs, targets = batch\n",
    "    assert np.array_equal(inputs[0], X[:sample_length])\n",
    "  \n",
    "    # second sample equals output timestamps 20-40\n",
    "    assert np.array_equal(targets[1], Y[sample_length:2*sample_length])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d43561",
   "metadata": {},
   "source": [
    "## pad_sequences function\n",
    "\n",
    "Pads sequences to the same length.\n",
    "\n",
    "This function transforms a `list (of length num_samples) of sequences (lists of integers)` into a `2D Numpy array of shape (num_samples, num_timesteps)`. num_timesteps is either the maxlen argument if provided, or the length of the longest sequence in the list.\n",
    "\n",
    "Sequences that are shorter than `num_timesteps` are padded with value until they are num_timesteps long.\n",
    "\n",
    "Sequences longer than num_timesteps are `truncated` so that they fit the desired length.\n",
    "\n",
    "The position where padding or truncation happens is determined by the arguments padding and truncating, respectively. `Pre-padding or removing values from the beginning of the sequence is the default`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ca24b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    sequences, maxlen=None, dtype=\"int32\", padding=\"pre\", truncating=\"pre\", value=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5f5b2d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 2, 3],\n",
       "       [4, 5, 6]], dtype=int32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = [[1], [2, 3], [4, 5, 6]]\n",
    "tf.keras.preprocessing.sequence.pad_sequences(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "68e84d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1, -1,  1],\n",
       "       [-1,  2,  3],\n",
       "       [ 4,  5,  6]], dtype=int32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.preprocessing.sequence.pad_sequences(sequence, value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bf992186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [2, 3, 0],\n",
       "       [4, 5, 6]], dtype=int32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.preprocessing.sequence.pad_sequences(sequence, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d3aaf942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [5, 6]], dtype=int32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.preprocessing.sequence.pad_sequences(sequence, maxlen=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49d5ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
